{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns that are irrelevant to the model\n",
    "data = data.drop(['Unnamed: 0', 'track_id', 'artists', 'album_name', 'track_name', 'popularity','Unnamed: 0'], axis=1)\n",
    "# remove time_signature, it's mostly 4/4 in this dataset\n",
    "data = data.drop(['time_signature'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class targets\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labEnc = LabelEncoder()\n",
    "y = data['track_genre']\n",
    "y = labEnc.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up traing and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, precision_score\n",
    "X = data.drop('track_genre', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Standard Scaler to standardize the numerical features. It removes the mean and scales each feature/variable to unit variance.\n",
    "# z-score normalization\n",
    "# transfroms data to have mean of 0 and standard deviation of 1\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "continuous_features = ['duration_ms', 'danceability', 'energy', 'loudness', \n",
    "                       'speechiness', 'acousticness', 'instrumentalness', \n",
    "                       'liveness', 'valence', 'tempo' ]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[continuous_features])\n",
    "X_train[continuous_features] = scaler.transform(X_train[continuous_features])\n",
    "X_test[continuous_features] = scaler.transform(X_test[continuous_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical features are already encoded as integers. Explicit and mode are already coded to 0 and 1. Key is an integer between 1 and 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Guess baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008771929824561403"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_counts = 114\n",
    "random_guessing_accuracy = 1 / genre_counts\n",
    "random_guessing_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy Classifier baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.008640350877192983, 0.008640350877192983)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_clf = DummyClassifier(strategy=\"stratified\", random_state=42)\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "y_pred = dummy_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='micro')\n",
    "accuracy, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random guess accruacy of 0.88% is very low, which is expected due to the large number of genres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1676315789473684, 0.16952590372637405)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree Classifier Baseline Model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "accuracy, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline accuracies:\n",
    "- Random Guess: 0.88%\n",
    "- Dummy Classifier: 0.86%\n",
    "- Decision Tree: 16.8%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuned Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_split': 70, 'max_depth': 40}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search for best parameters with RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'max_depth': list(range(10, 51, 10)),\n",
    "    'min_samples_split': list(range(10, 101, 20)),\n",
    "}\n",
    "random_search = RandomizedSearchCV(dt, param_grid, n_iter=25, cv=3, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "best_params_dt = random_search.best_params_\n",
    "best_params_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.18140350877192982, 0.17315301822343562)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and test with tuned parameters from RandomizedSearchCV\n",
    "best_params_dt = {'min_samples_split': 70, 'max_depth': 40}\n",
    "dt = DecisionTreeClassifier(**best_params_dt, random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "accuracy, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Classifier model accuracy: 18.1%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP CLassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1612719298245614"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a NN classifier for X to classify genre (y)\n",
    "# one hidden layer with # of neurons = # of features\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# mlp = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=100, random_state=42, early_stopping=True)\n",
    "# mlp = MLPClassifier(hidden_layer_sizes=(26, 26), max_iter=1000, random_state=42)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(13,), max_iter=100, random_state=42, early_stopping=True)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = mlp.predict(X_test_scaled)\n",
    "mlp_accuracy = accuracy_score(y_test, y_pred)\n",
    "mlp_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16912280701754387"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# two hidden layers, each with # of neurons = # of features\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(13,13), max_iter=100, random_state=42, early_stopping=True)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "y_pred = mlp.predict(X_test_scaled)\n",
    "mlp_accuracy = accuracy_score(y_test, y_pred)\n",
    "mlp_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17456140350877192"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# two hidden layers, 26 and 13 nodes each\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(26,13), max_iter=100, random_state=42, early_stopping=True)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "y_pred = mlp.predict(X_test_scaled)\n",
    "mlp_accuracy = accuracy_score(y_test, y_pred)\n",
    "mlp_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19478070175438597"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# two hidden layers, 26 and 13 nodes each\n",
    "# larger # of iterations\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(26,13), max_iter=500, random_state=42)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "y_pred = mlp.predict(X_test_scaled)\n",
    "mlp_accuracy = accuracy_score(y_test, y_pred)\n",
    "mlp_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19478070175438597"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# two hidden layers, 26 and 13 nodes each\n",
    "# larger # of iterations\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(26,13), max_iter=750, random_state=42)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "y_pred = mlp.predict(X_test_scaled)\n",
    "mlp_accuracy = accuracy_score(y_test, y_pred)\n",
    "mlp_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21653508771929825"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# two hidden layers of 100 neurons each, and train for 500 epochs\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,100), max_iter=500, random_state=42, early_stopping=True)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "y_pred = mlp.predict(X_test_scaled)\n",
    "mlp_accuracy = accuracy_score(y_test, y_pred)\n",
    "mlp_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nueral Network Model yielded an accuracy of 22.36%. This is an improvement over the tuned Decistion Tree model.  \n",
    "Next step is to tune the Nueral Network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't execute this block, takes too long\n",
    "# Search for best parameters for NN model with GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(13,), (13, 13), (26,13), (100, 100)],\n",
    "    'activation': ['relu', 'tanh', 'logistic'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [0.0001, 0.01, 1],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "}\n",
    "grid_search = GridSearchCV(mlp, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "best_params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV was stopped after an hour. Next we'll try RandomizedSearchCV with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of features in training data\n",
    "n_features = X_train.shape[1]\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': 'adam',\n",
       " 'hidden_layer_sizes': (100, 100),\n",
       " 'alpha': 0.01,\n",
       " 'activation': 'logistic'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune paramters with RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(13,), (13, 13), (26,13), (100, 100)],\n",
    "    'activation': ['relu', 'tanh', 'logistic'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [0.0001, 0.01, 1],\n",
    "}\n",
    "\n",
    "mlp = MLPClassifier(max_iter=500, random_state=42)\n",
    "random_search = RandomizedSearchCV(mlp, param_grid, n_iter=24, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "best_params_mlp = random_search.best_params_\n",
    "best_params_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.22416666666666665, 0.2055199126405463)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate the classifier with the best parameters\n",
    "best_params_mlp = {'solver': 'adam',\n",
    "    'hidden_layer_sizes': (100, 100),\n",
    "    'alpha': 0.01,\n",
    "    'activation': 'logistic'}\n",
    "mlp_best = MLPClassifier(**best_params_mlp, max_iter=500, random_state=42)\n",
    "mlp_best.fit(X_train_scaled, y_train)\n",
    "y_pred_best = mlp_best.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred_best)\n",
    "f1 = f1_score(y_test, y_pred_best, average='weighted')\n",
    "accuracy, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP model accuracy: 22.4%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2567982456140351"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "rf_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test_scaled)\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "rf_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune parameters with RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [5, 10, 13, 100, 200, 500],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt']\n",
    "}\n",
    "random_search_rf = RandomizedSearchCV(rf_clf, param_grid_rf, n_iter=20, cv=3, scoring='accuracy', n_jobs=-1, random_state=42, verbose=2)\n",
    "random_search_rf.fit(X_test_scaled, y_train)\n",
    "best_params_rf = random_search_rf.best_params_\n",
    "best_params_rf\n",
    "# 9 min 49s runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': None}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_rf = {'n_estimators': 200,\n",
    " 'min_samples_split': 10,\n",
    " 'min_samples_leaf': 1,\n",
    " 'max_features': 'sqrt',\n",
    " 'max_depth': None}\n",
    "best_params_rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2604385964912281, 0.24891698518745176)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tuned Random Forest Model\n",
    "best_params_rf = {'n_estimators': 200,\n",
    " 'min_samples_split': 10,\n",
    " 'min_samples_leaf': 1,\n",
    " 'max_features': 'sqrt',\n",
    " 'max_depth': None}\n",
    "rf_clf_best = RandomForestClassifier(**best_params_rf, random_state=42)\n",
    "rf_clf_best.fit(X_train, y_train)\n",
    "y_pred_rf_best = rf_clf_best.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_rf_best)\n",
    "f1 = f1_score(y_test, y_pred_rf_best, average='weighted')\n",
    "accuracy, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest model accuracy: 26%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb_clf = GradientBoostingClassifier(random_state=42)\n",
    "gb_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_gb = gb_clf.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test, y_pred_gb)\n",
    "gb_accuracy\n",
    "# 0.216"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting model accuracy: 21.6%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alec\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Alec\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.14619298245614035"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM Model\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "svm_clf = svm.LinearSVC(random_state=42)\n",
    "svm_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_svm = svm_clf.predict(X_test_scaled)\n",
    "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "svm_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM model accuracy: 14.6%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg_clf = LogisticRegression(random_state=42)\n",
    "log_reg_clf.fit(X_train, y_train)\n",
    "y_pred_log_reg = log_reg_clf.predict(X_test)\n",
    "log_reg_accuracy = accuracy_score(y_test, y_pred_log_reg)\n",
    "log_reg_accuracy\n",
    "# 0.1679"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16785964912280701"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LogisticRegression with higher max_iter\n",
    "log_reg_clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_reg_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_log_reg = log_reg_clf.predict(X_test_scaled)\n",
    "log_reg_accuracy = accuracy_score(y_test, y_pred_log_reg)\n",
    "log_reg_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression model accuracy: 16.8%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Stacking Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# base models\n",
    "level0 = list()\n",
    "level0.append(('lr', LogisticRegression(max_iter=100000)))\n",
    "level0.append(('rf', RandomForestClassifier(n_estimators=200, min_samples_split=2, min_samples_leaf=1, max_features='sqrt', max_depth=30)))\n",
    "level0.append(('svm', svm.LinearSVC()))\n",
    "\n",
    "# meta learner model\n",
    "level1 = LogisticRegression()\n",
    "stacking_model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
    "stacking_model.fit(X_train_scaled, y_train)\n",
    "y_pred_stacking = stacking_model.predict(X_test_scaled)\n",
    "stacking_accuracy = accuracy_score(y_test, y_pred_stacking)\n",
    "stacking_accuracy\n",
    "# accuracy: 0.2718"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27.18% accuracy for Ensemble stack of Logistic Regression, Random Forest, and SVM models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alec\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Alec\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Alec\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Alec\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3377631578947368, 0.33274350568541206)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stacking Model Random Forest, Decision Tree, and MLP\n",
    "\n",
    "# imports and paramters defined here for convenience\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "best_params_rf = {'n_estimators': 200,\n",
    "    'min_samples_split': 10,\n",
    "    'min_samples_leaf': 1,\n",
    "    'max_features': 'sqrt',\n",
    "    'max_depth': None}\n",
    "best_params_dt = {'min_samples_split': 70, 'max_depth': 40}\n",
    "best_params_mlp = {'solver': 'adam',\n",
    "    'hidden_layer_sizes': (100, 100),\n",
    "    'alpha': 0.01,\n",
    "    'activation': 'logistic'}\n",
    "\n",
    "# base models\n",
    "level0 = list()\n",
    "level0.append(('rf', RandomForestClassifier(**best_params_rf, random_state=42)))\n",
    "level0.append(('dt', DecisionTreeClassifier(**best_params_dt, random_state=42)))\n",
    "level0.append(('mlp', MLPClassifier(**best_params_mlp, max_iter=500, random_state=42)))\n",
    "\n",
    "# meta learner model\n",
    "level1 = LogisticRegression()\n",
    "\n",
    "# stacking model\n",
    "stacking_model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
    "stacking_model.fit(X_train_scaled, y_train)\n",
    "y_pred_stacking = stacking_model.predict(X_test_scaled)\n",
    "stacking_accuracy = accuracy_score(y_test, y_pred_stacking)\n",
    "f1 = f1_score(y_test, y_pred_stacking, average='weighted')\n",
    "stacking_accuracy, f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "33.8% accuracy for Ensemble stack of DecisionTreeClassifier, RandomForestClassifier, MLPclassifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
